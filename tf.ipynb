{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a214dfa6-937f-4306-bf82-911785775ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.utils import common\n",
    "\n",
    "\n",
    "import abc\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50d15a00-3a86-45be-ad76-27dfc546865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c5a1a6-7e44-4c9f-9620-f84bb5cdb1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캐글 데이터\n",
    "df = pd.read_csv('G://내 드라이브/Github/Predictiong_MBTI_for_Internet_Users/MBTI 500.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21681be3-3c63-480b-a58e-d1ac8df11067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['text', 'type']\n",
    "df = df[['type', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b318a78b-4193-4862-ab37-3c69d37a7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 106067/106067 [00:20<00:00, 5217.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#function to clean the text data\n",
    "def clear_text(data):\n",
    "    data_length=[]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    cleaned_text=[]\n",
    "    for sentence in tqdm(data.text):\n",
    "        sentence=sentence.lower()\n",
    "#         removing links from text data\n",
    "        sentence=re.sub('https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+',' ',sentence)\n",
    "#         removing other symbols\n",
    "        sentence=re.sub('[^0-9a-z]',' ',sentence)\n",
    "        data_length.append(len(sentence.split()))\n",
    "        cleaned_text.append(sentence)\n",
    "    return cleaned_text,data_length\n",
    "\n",
    "df.text, _=clear_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37784595-92c4-4b13-9831-32a18cfc47d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text'] # features\n",
    "y = df['type']  # labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "571aa18a-1488-4409-bdb8-2ac94b64ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelining the vectorizer and the classifier\n",
    "text_clf1 = Pipeline([('tfidf',TfidfVectorizer(sublinear_tf = True)),('clf',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed469971-ae74-4491-85b2-37899a067135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(sublinear_tf=True)),\n",
       "                ('clf', LinearSVC())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07c9f14f-2fa1-4ee6-a628-5bb62f02a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = text_clf1.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478facc-8eb3-4f1a-8420-6f91e9563105",
   "metadata": {},
   "source": [
    "+++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3174eaad-3f4e-4295-b36f-93f5add7054b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4975d37-07be-4981-bfe4-f123a91075aa",
   "metadata": {},
   "source": [
    "### 하이퍼 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "889ea8e8-f6b1-46f4-adfd-9abb1ec9dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 4 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 2  # @param {type:\"integer\"} \n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 2  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 2# @param {type:\"integer\"}\n",
    "eval_interval = 2  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3edd80c1-d8f6-4a5a-a139-8f01a80889dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "dcbccc5a-f305-4efc-963b-ba17123dda09",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = list()\n",
    "\n",
    "class LinegameEnv(py_environment.PyEnvironment):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.int32, minimum=0, maximum=100, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "        shape=(1,), dtype=np.int32, minimum=0, name='observation')\n",
    "        self._state = 0.1\n",
    "        self._time = 1\n",
    "        self._episode_ended = False\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        self._state = 0.1\n",
    "        self._time = 1\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "    def _step(self, action):\n",
    "        if self._episode_ended:\n",
    "            self.reset()\n",
    "        elif self._time==1: \n",
    "            print(\"### new episode start! ###\")\n",
    "            print(\" \")\n",
    "        else: \n",
    "            print(\" \")\n",
    "        \n",
    "        print(\"{}-1. current state = {}\".format(self._time,self._state))\n",
    "        \n",
    "        # Pipelining the vectorizer and the classifier\n",
    "        text_clf1 = Pipeline([('tfidf',TfidfVectorizer(sublinear_tf = True)),('clf',LinearSVC(C= self._state))])\n",
    "        text_clf1.fit(X_train, y_train)\n",
    "        \n",
    "        reward = metrics.accuracy_score(y_val, text_clf1.predict(X_val))\n",
    "        \n",
    "        #self._state += (action-500)/500\n",
    "        #print(\"{}-2. action = {}\".format(self._time,(action-500)/500))\n",
    "        self._state += (action-50)/500\n",
    "        print(\"{}-2. action = {}\".format(self._time,(action-50)/500))\n",
    "        \n",
    "        \n",
    "        if self._state < 0.1:\n",
    "          print(\"    **exit(current state<0.1) => reset current state as 0.**\")\n",
    "          self._state = 0.1\n",
    "        if self._state > 1.0 : \n",
    "          print(\"   **exit(current state >1.0) => reset current state as 1.**\")\n",
    "          self._state = 1.0\n",
    "        \n",
    "        print(\"{}-3. reward = {}\".format(self._time,reward))\n",
    "        returns.append(reward) ############################# !!!\n",
    "        \n",
    "        print(\"{}-4. future state = {}\".format(self._time,self._state))\n",
    "        \n",
    "        self._time += 1\n",
    "        if self._time > 4: self._episode_ended = True\n",
    "        \n",
    "        if self._episode_ended:\n",
    "            print(\" \")\n",
    "            print(\"### episode ended ###\")\n",
    "            return ts.termination(np.array([self._state], dtype=np.int32), reward)\n",
    "        else:\n",
    "            return ts.transition(np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "97396a5b-a99a-4c65-a426-62155444a07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### new episode start! ###\n",
      " \n",
      "1-1. current state = 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-195-728fa577a2a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0menvironment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinegameEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_py_environment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvironment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepisodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tf_agents\\environments\\utils.py\u001b[0m in \u001b[0;36mvalidate_py_environment\u001b[1;34m(environment, episodes, observation_and_action_constraint_splitter)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_policy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mtime_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mepisode_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_last\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tf_agents\\environments\\py_environment.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    230\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_time_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_time_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-194-3fa89e760f48>\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# Pipelining the vectorizer and the classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mtext_clf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tfidf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msublinear_tf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mtext_clf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext_clf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \"\"\"\n\u001b[0;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1119\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                         \u001b[0mfeature_counter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m                     \u001b[1;31m# Ignore out-of-vocabulary items for fixed_vocab=True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "environment = LinegameEnv()\n",
    "utils.validate_py_environment(environment, episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "30db82bc-9f86-4477-b22c-f8fca0e0004f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8440652399358914,\n",
       " 0.8440652399358914,\n",
       " 0.8440652399358914,\n",
       " 0.844442349391911,\n",
       " 0.8448194588479306,\n",
       " 0.8451965683039502,\n",
       " 0.8460450645799943,\n",
       " 0.8459507872159895,\n",
       " 0.8466107287640238,\n",
       " 0.8462336193080041,\n",
       " 0.846327896672009,\n",
       " 0.8459507872159895,\n",
       " 0.8457622324879797,\n",
       " 0.8452908456679551,\n",
       " 0.8456679551239747,\n",
       " 0.8451965683039502,\n",
       " 0.8451965683039502,\n",
       " 0.8459507872159895,\n",
       " 0.8459507872159895,\n",
       " 0.8451965683039502,\n",
       " 0.8461393419439992,\n",
       " 0.8460450645799943,\n",
       " 0.8460450645799943,\n",
       " 0.8457622324879797,\n",
       " 0.8451022909399453,\n",
       " 0.8459507872159895,\n",
       " 0.8459507872159895,\n",
       " 0.8462336193080041,\n",
       " 0.846327896672009,\n",
       " 0.8462336193080041,\n",
       " 0.846327896672009,\n",
       " 0.8456679551239747,\n",
       " 0.8451965683039502,\n",
       " 0.8451965683039502,\n",
       " 0.8449137362119356,\n",
       " 0.8451965683039502,\n",
       " 0.8450080135759405,\n",
       " 0.843499575751862,\n",
       " 0.8441595172998962,\n",
       " 0.8446309041199208,\n",
       " 0.8452908456679551,\n",
       " 0.8441595172998962,\n",
       " 0.844442349391911,\n",
       " 0.8450080135759405,\n",
       " 0.8449137362119356,\n",
       " 0.8449137362119356,\n",
       " 0.8452908456679551,\n",
       " 0.8452908456679551,\n",
       " 0.8445366267559159,\n",
       " 0.8448194588479306,\n",
       " 0.8451965683039502,\n",
       " 0.8452908456679551,\n",
       " 0.8451965683039502,\n",
       " 0.8451965683039502,\n",
       " 0.8458565098519846,\n",
       " 0.8451022909399453,\n",
       " 0.8446309041199208,\n",
       " 0.844442349391911,\n",
       " 0.8438766852078816,\n",
       " 0.8440652399358914,\n",
       " 0.8439709625718865,\n",
       " 0.8440652399358914,\n",
       " 0.844442349391911,\n",
       " 0.8451965683039502,\n",
       " 0.8460450645799943,\n",
       " 0.8461393419439992,\n",
       " 0.8458565098519846,\n",
       " 0.8451022909399453,\n",
       " 0.8435938531158669,\n",
       " 0.8439709625718865,\n",
       " 0.8440652399358914,\n",
       " 0.8440652399358914,\n",
       " 0.843499575751862,\n",
       " 0.8436881304798718]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9abe44bf-55d8-4d35-80cf-19b30f31d1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#iterations = range(0, 2*7 + 1, 1)\n",
    "iterations = range(0,74)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "29481664-2f3c-4dc7-ba62-0406743ca5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = LinegameEnv\n",
    "eval_py_env = LinegameEnv\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fe0b61-a405-4327-a9b5-a77d770e26fc",
   "metadata": {},
   "source": [
    "### 에이전트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c6f70fba-e29f-4f39-b920-b3cb4f62602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100,)\n",
    "q_net = q_network.QNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_step_counter = tf.Variable(0)\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cd3c2c-ff20-4fec-b48f-b6bd02efbd71",
   "metadata": {},
   "source": [
    "### Policies\n",
    "\n",
    "A policy defines the way an agent acts in an environment. Typically, the goal of reinforcement learning is to train the underlying model until the policy produces the desired outcome.\n",
    "\n",
    "In this tutorial:\n",
    "\n",
    "-   The desired outcome is keeping the pole balanced upright over the cart.\n",
    "-   The policy returns an action (left or right) for each `time_step` observation.\n",
    "\n",
    "Agents contain two policies: \n",
    "\n",
    "-   `agent.policy` — The main policy that is used for evaluation and deployment.\n",
    "-   `agent.collect_policy` — A second policy that is used for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6e90c60e-0d1e-41b2-b0c6-2a45033e2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed967874-eb82-4041-a137-46170d890790",
   "metadata": {},
   "source": [
    "Policies can be created independently of agents. For example, use `tf_agents.policies.random_tf_policy` to create a policy which will randomly select an action for each `time_step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a679b831-73c5-4965-b435-449d05e7104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f669e6ca-e991-436e-85fb-c8b5f5697de7",
   "metadata": {},
   "source": [
    "To get an action from a policy, call the `policy.action(time_step)` method. The `time_step` contains the observation from the environment. This method returns a `PolicyStep`, which is a named tuple with three components:\n",
    "\n",
    "-   `action` — the action to be taken (in this case, `0` or `1`)\n",
    "-   `state` — used for stateful (that is, RNN-based) policies\n",
    "-   `info` — auxiliary data, such as log probabilities of actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439c44c-e78c-46f5-914d-d1be049cef21",
   "metadata": {},
   "source": [
    "### Metrics and Evaluation\n",
    "\n",
    "The most common metric used to evaluate a policy is the average return. The return is the sum of rewards obtained while running a policy in an environment for an episode. Several episodes are run, creating an average return.\n",
    "\n",
    "The following function computes the average return of a policy, given the policy, environment, and a number of episodes.\n",
    "\n",
    "정책을 평가하는 데 사용되는 가장 일반적인 메트릭은 평균 수익률입니다. 수익률은 한 에피소드에 대한 환경에서 정책을 실행하는 동안 얻은 보상의 합계입니다. 몇 개의 에피소드가 실행되어 평균 수익을 창출합니다. 다음 함수는 정책, 환경 및 에피소드 수에 따라 정책의 평균 수익률을 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3dbcc350-de50-4d9b-a41b-6f1f35d053d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "953834ae-d8ab-46a8-84c9-29fe7cdea7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fcb6ac89-a4e6-45b9-b7d1-982cb4e0eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "            print(f\"{time_step.reward} 현재의 리워드다다다다다\")\n",
    "        total_return += episode_return\n",
    "        print(f\"{episode_return}이다다다ㅏ다다\")\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0d5ce-9d0b-45fb-9069-8b65b0a04d4d",
   "metadata": {},
   "source": [
    "Running this computation on the `random_policy` shows a baseline performance in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "894a8815-c7c6-4519-9a6a-b99784026327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### new episode start! ###\n",
      " \n",
      "1-1. current state = 0.1\n",
      "1-2. action = -0.062\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.1\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "2-1. current state = 0.1\n",
      "2-2. action = -0.038\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "2-3. reward = 0.8407655321957198\n",
      "2-4. future state = 0.1\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "3-1. current state = 0.1\n",
      "3-2. action = -0.082\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "3-3. reward = 0.8407655321957198\n",
      "3-4. future state = 0.1\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "4-1. current state = 0.1\n",
      "4-2. action = 0.0\n",
      "4-3. reward = 0.8407655321957198\n",
      "4-4. future state = 0.1\n",
      " \n",
      "### episode ended ###\n",
      "[0.84076554] 현재의 리워드다다다다다\n",
      "[0.84076554]이다다다ㅏ다다\n",
      "### new episode start! ###\n",
      " \n",
      "1-1. current state = 0.1\n",
      "1-2. action = 0.05\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.15000000000000002\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "2-1. current state = 0.15000000000000002\n",
      "2-2. action = 0.052\n",
      "2-3. reward = 0.8470821155840482\n",
      "2-4. future state = 0.202\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "3-1. current state = 0.202\n",
      "3-2. action = 0.058\n",
      "3-3. reward = 0.8481191665881022\n",
      "3-4. future state = 0.26\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "4-1. current state = 0.26\n",
      "4-2. action = 0.038\n",
      "4-3. reward = 0.8499104365041953\n",
      "4-4. future state = 0.298\n",
      " \n",
      "### episode ended ###\n",
      "[0.84991044] 현재의 리워드다다다다다\n",
      "[0.84991044]이다다다ㅏ다다\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.845338"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af19265a-86e6-4792-a73b-8530626e1dff",
   "metadata": {},
   "source": [
    "### Replay Buffer\n",
    "\n",
    "The replay buffer keeps track of data collected from the environment. This tutorial uses `tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer`, as it is the most common. \n",
    "\n",
    "The constructor requires the specs for the data it will be collecting. This is available from the agent using the `collect_data_spec` method. The batch size and maximum buffer length are also required.\n",
    "\n",
    "재생 버퍼는 환경에서 수집된 데이터를 추적합니다. 이 자습서에서는 tf_agents.replay_buffers.tf_uniform_replay_buffer를 사용합니다.가장 일반적인 TFUniformReplayBuffer입니다. 생성자는 수집할 데이터에 대한 사양을 요구합니다. 이 기능은 collect_data_spec 메서드를 사용하여 에이전트에서 사용할 수 있습니다. 배치 크기와 최대 버퍼 길이도 필요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2d288b12-690d-4efa-9e69-bcb5226521a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd3640-3827-4b78-9cd0-14e4fc92c372",
   "metadata": {},
   "source": [
    "For most agents, `collect_data_spec` is a named tuple called `Trajectory`, containing the specs for observations, actions, rewards, and other items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ab33d472-3a88-4402-9158-6e2b363c7751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trajectory(\n",
       "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0), maximum=array(100)),\n",
       " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
       " 'observation': BoundedTensorSpec(shape=(1,), dtype=tf.int32, name='observation', minimum=array(0), maximum=array(2147483647)),\n",
       " 'policy_info': (),\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b328aeab-9cc8-43ac-afda-dc7b0eb3caff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('step_type',\n",
       " 'observation',\n",
       " 'action',\n",
       " 'policy_info',\n",
       " 'next_step_type',\n",
       " 'reward',\n",
       " 'discount')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec._fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772fab0a-1d89-4d2a-884e-8086b4e1f025",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "Now execute the random policy in the environment for a few steps, recording the data in the replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a8340a15-7519-4b39-83c2-779556cc602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "3-1. current state = 0.1\n",
      "3-2. action = -0.056\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "3-3. reward = 0.8407655321957198\n",
      "3-4. future state = 0.1\n",
      " \n",
      "4-1. current state = 0.1\n",
      "4-2. action = 0.086\n",
      "4-3. reward = 0.8407655321957198\n",
      "4-4. future state = 0.186\n",
      " \n",
      "### episode ended ###\n",
      "1-1. current state = 0.1\n",
      "1-2. action = -0.058\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.1\n",
      " \n",
      "2-1. current state = 0.1\n",
      "2-2. action = -0.038\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "2-3. reward = 0.8407655321957198\n",
      "2-4. future state = 0.1\n",
      " \n",
      "3-1. current state = 0.1\n",
      "3-2. action = 0.026\n",
      "3-3. reward = 0.8407655321957198\n",
      "3-4. future state = 0.126\n",
      " \n",
      "4-1. current state = 0.126\n",
      "4-2. action = 0.094\n",
      "4-3. reward = 0.8438766852078816\n",
      "4-4. future state = 0.22\n",
      " \n",
      "### episode ended ###\n",
      "1-1. current state = 0.1\n",
      "1-2. action = 0.006\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.10600000000000001\n",
      " \n",
      "2-1. current state = 0.10600000000000001\n",
      "2-2. action = 0.076\n",
      "2-3. reward = 0.8413311963797492\n",
      "2-4. future state = 0.182\n",
      " \n",
      "3-1. current state = 0.182\n",
      "3-2. action = -0.084\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "3-3. reward = 0.8481191665881022\n",
      "3-4. future state = 0.1\n",
      " \n",
      "4-1. current state = 0.1\n",
      "4-2. action = -0.064\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "4-3. reward = 0.8407655321957198\n",
      "4-4. future state = 0.1\n",
      " \n",
      "### episode ended ###\n"
     ]
    }
   ],
   "source": [
    "def collect_step(environment, policy, buffer):\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "    # Add trajectory to the replay buffer\n",
    "    buffer.add_batch(traj)\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "    for _ in range(steps):\n",
    "        collect_step(env, policy, buffer)\n",
    "\n",
    "collect_data(train_env, random_policy, replay_buffer, steps=10)\n",
    "\n",
    "# This loop is so common in RL, that we provide standard implementations. \n",
    "# For more details see the drivers module.\n",
    "# https://www.tensorflow.org/agents/api_docs/python/tf_agents/drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbcfb50-6e21-4e2b-a1fa-8c92adebdbab",
   "metadata": {},
   "source": [
    "The replay buffer is now a collection of Trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9582980c-f8b1-4adc-8151-e1854bf9ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the curious:\n",
    "# Uncomment to peel one of these off and inspect it.\n",
    "# iter(replay_buffer.as_dataset()).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b88f79-45a4-4620-9b84-5e3110562a05",
   "metadata": {},
   "source": [
    "The agent needs access to the replay buffer. This is provided by creating an iterable `tf.data.Dataset` pipeline which will feed data to the agent.\n",
    "\n",
    "Each row of the replay buffer only stores a single observation step. But since the DQN Agent needs both the current and next observation to compute the loss, the dataset pipeline will sample two adjacent rows for each item in the batch (`num_steps=2`).\n",
    "\n",
    "This dataset is also optimized by running parallel calls and prefetching data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "29a6ba62-edaa-4414-a08f-ec7aef72e2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(Trajectory(\n",
       "{'action': TensorSpec(shape=(2, 2), dtype=tf.int32, name=None),\n",
       " 'discount': TensorSpec(shape=(2, 2), dtype=tf.float32, name=None),\n",
       " 'next_step_type': TensorSpec(shape=(2, 2), dtype=tf.int32, name=None),\n",
       " 'observation': TensorSpec(shape=(2, 2, 1), dtype=tf.int32, name=None),\n",
       " 'policy_info': (),\n",
       " 'reward': TensorSpec(shape=(2, 2), dtype=tf.float32, name=None),\n",
       " 'step_type': TensorSpec(shape=(2, 2), dtype=tf.int32, name=None)}), BufferInfo(ids=TensorSpec(shape=(2, 2), dtype=tf.int64, name=None), probabilities=TensorSpec(shape=(2,), dtype=tf.float32, name=None)))>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "817fe5f9-5f0f-4009-a854-2cf12987ab3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x0000026D2E11B130>\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset)\n",
    "\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "72e14f16-d4b6-4ad5-96c7-fcbb1b96374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the curious:\n",
    "# Uncomment to see what the dataset iterator is feeding to the agent.\n",
    "# Compare this representation of replay data \n",
    "# to the collection of individual trajectories shown earlier.\n",
    "\n",
    "# iterator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3f375-becf-4212-82ea-367dc8085c02",
   "metadata": {},
   "source": [
    "### Training the agent\n",
    "\n",
    "Two things must happen during the training loop:\n",
    "\n",
    "-   collect data from the environment\n",
    "-   use that data to train the agent's neural network(s)\n",
    "\n",
    "This example also periodicially evaluates the policy and prints the current score.\n",
    "\n",
    "The following will take ~5 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "aa52b1d4-c6ef-4192-946d-b4b45cf34028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### new episode start! ###\n",
      " \n",
      "1-1. current state = 0.1\n",
      "1-2. action = -0.1\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.1\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "2-1. current state = 0.1\n",
      "2-2. action = -0.1\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "2-3. reward = 0.8407655321957198\n",
      "2-4. future state = 0.1\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "3-1. current state = 0.1\n",
      "3-2. action = -0.1\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "3-3. reward = 0.8407655321957198\n",
      "3-4. future state = 0.1\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "4-1. current state = 0.1\n",
      "4-2. action = -0.1\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "4-3. reward = 0.8407655321957198\n",
      "4-4. future state = 0.1\n",
      " \n",
      "### episode ended ###\n",
      "[0.84076554] 현재의 리워드다다다다다\n",
      "[0.84076554]이다다다ㅏ다다\n",
      "### new episode start! ###\n",
      " \n",
      "1-1. current state = 0.1\n",
      "1-2. action = -0.1\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.1\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "2-1. current state = 0.1\n",
      "2-2. action = -0.1\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "2-3. reward = 0.8407655321957198\n",
      "2-4. future state = 0.1\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "3-1. current state = 0.1\n",
      "3-2. action = -0.1\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "3-3. reward = 0.8407655321957198\n",
      "3-4. future state = 0.1\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "4-1. current state = 0.1\n",
      "4-2. action = -0.1\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "4-3. reward = 0.8407655321957198\n",
      "4-4. future state = 0.1\n",
      " \n",
      "### episode ended ###\n",
      "[0.84076554] 현재의 리워드다다다다다\n",
      "[0.84076554]이다다다ㅏ다다\n",
      "1-1. current state = 0.1\n",
      "1-2. action = -0.1\n",
      "    **exit(current state<0.1) => reset current state as 0.**\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.1\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <tensorflow.python.eager.def_function.Function object at 0x0000026D2DDD5C70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <tensorflow.python.eager.def_function.Function object at 0x0000026D2DDD5C70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "2-1. current state = 0.1\n",
      "2-2. action = 0.094\n",
      "2-3. reward = 0.8407655321957198\n",
      "2-4. future state = 0.194\n",
      "### new episode start! ###\n",
      " \n",
      "1-1. current state = 0.1\n",
      "1-2. action = 0.094\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.194\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "2-1. current state = 0.194\n",
      "2-2. action = 0.094\n",
      "2-3. reward = 0.8484019986801169\n",
      "2-4. future state = 0.28800000000000003\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "3-1. current state = 0.28800000000000003\n",
      "3-2. action = 0.094\n",
      "3-3. reward = 0.849250494956161\n",
      "3-4. future state = 0.382\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "4-1. current state = 0.382\n",
      "4-2. action = 0.094\n",
      "4-3. reward = 0.8489676628641463\n",
      "4-4. future state = 0.476\n",
      " \n",
      "### episode ended ###\n",
      "[0.8489677] 현재의 리워드다다다다다\n",
      "[0.8489677]이다다다ㅏ다다\n",
      "### new episode start! ###\n",
      " \n",
      "1-1. current state = 0.1\n",
      "1-2. action = 0.094\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.194\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "2-1. current state = 0.194\n",
      "2-2. action = 0.094\n",
      "2-3. reward = 0.8484019986801169\n",
      "2-4. future state = 0.28800000000000003\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "3-1. current state = 0.28800000000000003\n",
      "3-2. action = 0.094\n",
      "3-3. reward = 0.849250494956161\n",
      "3-4. future state = 0.382\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "4-1. current state = 0.382\n",
      "4-2. action = 0.094\n",
      "4-3. reward = 0.8489676628641463\n",
      "4-4. future state = 0.476\n",
      " \n",
      "### episode ended ###\n",
      "[0.8489677] 현재의 리워드다다다다다\n",
      "[0.8489677]이다다다ㅏ다다\n",
      "step = 2: Average Return = 0.8489676713943481\n",
      " \n",
      "3-1. current state = 0.194\n",
      "3-2. action = 0.094\n",
      "3-3. reward = 0.8484019986801169\n",
      "3-4. future state = 0.28800000000000003\n",
      " \n",
      "4-1. current state = 0.28800000000000003\n",
      "4-2. action = -0.074\n",
      "4-3. reward = 0.849250494956161\n",
      "4-4. future state = 0.21400000000000002\n",
      " \n",
      "### episode ended ###\n",
      "### new episode start! ###\n",
      " \n",
      "1-1. current state = 0.1\n",
      "1-2. action = 0.094\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.194\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "2-1. current state = 0.194\n",
      "2-2. action = 0.094\n",
      "2-3. reward = 0.8484019986801169\n",
      "2-4. future state = 0.28800000000000003\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "3-1. current state = 0.28800000000000003\n",
      "3-2. action = 0.094\n",
      "3-3. reward = 0.849250494956161\n",
      "3-4. future state = 0.382\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "4-1. current state = 0.382\n",
      "4-2. action = 0.094\n",
      "4-3. reward = 0.8489676628641463\n",
      "4-4. future state = 0.476\n",
      " \n",
      "### episode ended ###\n",
      "[0.8489677] 현재의 리워드다다다다다\n",
      "[0.8489677]이다다다ㅏ다다\n",
      "### new episode start! ###\n",
      " \n",
      "1-1. current state = 0.1\n",
      "1-2. action = 0.094\n",
      "1-3. reward = 0.8407655321957198\n",
      "1-4. future state = 0.194\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "2-1. current state = 0.194\n",
      "2-2. action = 0.094\n",
      "2-3. reward = 0.8484019986801169\n",
      "2-4. future state = 0.28800000000000003\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "3-1. current state = 0.28800000000000003\n",
      "3-2. action = 0.094\n",
      "3-3. reward = 0.849250494956161\n",
      "3-4. future state = 0.382\n",
      "[0.] 현재의 리워드다다다다다\n",
      " \n",
      "4-1. current state = 0.382\n",
      "4-2. action = 0.094\n",
      "4-3. reward = 0.8489676628641463\n",
      "4-4. future state = 0.476\n",
      " \n",
      "### episode ended ###\n",
      "[0.8489677] 현재의 리워드다다다다다\n",
      "[0.8489677]이다다다ㅏ다다\n",
      "step = 4: Average Return = 0.8489676713943481\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %%time\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "    for _ in range(collect_steps_per_iteration):\n",
    "        collect_step(train_env, agent.collect_policy, replay_buffer)\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(iterator)\n",
    "    train_loss = agent.train(experience).loss\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96669f69-ca6e-4528-a274-3e6fe36aa939",
   "metadata": {},
   "source": [
    "### Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a3f1f-5c8d-4e34-ac1b-778e3d40cadb",
   "metadata": {},
   "source": [
    "### Plots\n",
    "\n",
    "Use `matplotlib.pyplot` to chart how the policy improved during training.\n",
    "\n",
    "One iteration of `Cartpole-v0` consists of 200 time steps. The environment gives a reward of `+1` for each step the pole stays up, so the maximum return for one episode is 200. The charts shows the return increasing towards that maximum each time it is evaluated during training. (It may be a little unstable and not increase monotonically each time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "39d1e170-ccbb-4978-b696-101b29fffaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.84076554,\n",
       " 0.8407655321957198,\n",
       " 0.8407655321957198,\n",
       " 0.8407655321957198,\n",
       " 0.8484019986801169,\n",
       " 0.849250494956161,\n",
       " 0.8489676628641463,\n",
       " 0.8484019986801169,\n",
       " 0.849250494956161,\n",
       " 0.8489676628641463,\n",
       " 0.8489677,\n",
       " 0.8484019986801169,\n",
       " 0.849250494956161,\n",
       " 0.8484019986801169,\n",
       " 0.849250494956161,\n",
       " 0.8489676628641463,\n",
       " 0.8484019986801169,\n",
       " 0.849250494956161,\n",
       " 0.8489676628641463,\n",
       " 0.8489677]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8ce27f39-61e5-458b-b4af-37525c8ff637",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = [0.84076554,\n",
    " 0.8407655321957198,\n",
    " 0.8407655321957198,\n",
    " 0.8407655321957198,\n",
    " 0.8484019986801169,\n",
    " 0.849250494956161,\n",
    " 0.8489676628641463,\n",
    " 0.8484019986801169,\n",
    " 0.849250494956161,\n",
    " 0.8489676628641463,\n",
    " 0.8489677,\n",
    " 0.8484019986801169,\n",
    " 0.849250494956161,\n",
    " 0.8484019986801169,\n",
    " 0.849250494956161,\n",
    " 0.8489676628641463,\n",
    " 0.8484019986801169,\n",
    " 0.849250494956161,\n",
    " 0.8489676628641463,\n",
    " 0.8489677]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ad1d7b56-4462-4a6f-808e-e4c60664b92e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (3,) and (20,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-247-071649ace972>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_interval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Average Return'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iterations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2838\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2839\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2840\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2841\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2842\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1741\u001b[0m         \"\"\"\n\u001b[0;32m   1742\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1743\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1744\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    400\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (3,) and (20,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d64e7811-4eec-467d-8f9d-c2e4e4ac760a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = range(0,20)\n",
    "\n",
    "\n",
    "#iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0e4e3-3c51-446d-81ce-4708e7c6a284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
